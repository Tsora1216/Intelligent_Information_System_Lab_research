{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "教授にプレゼン後、データの保存をし、テーブルとして値を持つ必要があることがわかった\n",
    "大きなデータになるので保存方法を考慮する必要があった。\n",
    "CSV、Excel、バイナリ、HDF5が候補として挙がった。\n",
    "HDF5形式は大容量のデータセットを効率的に保存するためのファイル形式であるため、採択。\n",
    "参考サイトの少なさから一時的にSQLを採択\n",
    "SQLをテストし、全語句のデータの保存をしてみた\n",
    "SQLでは、VisualStudioCodeの拡張機能が使いづらく、SQLite3に変更した\n",
    "SQLite->dataframe->変更->dataframe->変更を保存->SQLiteの完成\n",
    "上記の方法では変更件数に関わらず、全件で1分30秒かかる。\n",
    "変更に時間がかかりすぎな点が課題であるため、データの更新方法を検討\n",
    "SQLからPythonに値を渡さず、直接書き込むことで一件当たり0.1秒以内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 学習済みモデルのロード\n",
    "model_file_path = '../../KITERETU/gw2v160.model'\n",
    "model = Word2Vec.load(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import sqlite3\n",
    "\n",
    "# データベースに接続し、カーソルを作成する\n",
    "conn = sqlite3.connect('database2.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# テーブルが存在しない場合のみ作成する\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS words (word TEXT, value REAL)''')\n",
    "\n",
    "# モデル内のすべての単語と値をデータベースに保存する\n",
    "for word in model.wv.key_to_index:\n",
    "    cursor.execute('''INSERT INTO words VALUES (?, ?)''', (word, 0.000000))\n",
    "\n",
    "# コミットして変更を確定する\n",
    "conn.commit()\n",
    "\n",
    "# データベース接続を閉じる\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# データベースに接続する\n",
    "conn = sqlite3.connect('database2.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# データの更新を行う\n",
    "cursor.execute(\"UPDATE words SET value = ? WHERE word = ?\", (0.20000, '其の'))\n",
    "\n",
    "# コミットして変更を確定する\n",
    "conn.commit()\n",
    "\n",
    "# データベース接続を閉じる\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "群馬に類似する文字列とその類似度は以下の通り\n",
      "群馬県 \t 0.7760874032974243\n",
      "栃木 \t 0.7456161379814148\n",
      "前橋 \t 0.7389767169952393\n",
      "埼玉 \t 0.7216979265213013\n",
      "高崎 \t 0.6891007423400879\n",
      "伊勢崎 \t 0.6693983674049377\n",
      "茨城 \t 0.6651455163955688\n",
      "高崎市 \t 0.6536263227462769\n",
      "群馬県前橋市 \t 0.6474608778953552\n",
      "栃木県 \t 0.6421990990638733\n"
     ]
    }
   ],
   "source": [
    "input_str=input(\"意味類似度ネットワークを作りたい単語を入力してください===>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 似ている単語TOP7を書き出す\n",
    "out = model.wv.most_similar(positive=[input_str], topn=3)\n",
    "\n",
    "#AtCoderでよく使う辞書処理を使って県と数値を取り出す\n",
    "pre=[]\n",
    "pre.append(input_str)\n",
    "for prefecture, value in out:\n",
    "    print(prefecture,\"\\t\",value)\n",
    "    pre.append(prefecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "群馬県 \t 0.7760874032974243\n",
      "栃木 \t 0.7456161379814148\n",
      "前橋 \t 0.7389767169952393\n",
      "群馬県 \t 0.7760874032974243\n",
      "栃木 \t 0.7456161379814148\n",
      "前橋 \t 0.7389767169952393\n",
      "群馬県 \t 0.7760874032974243\n",
      "栃木 \t 0.7456161379814148\n",
      "前橋 \t 0.7389767169952393\n"
     ]
    }
   ],
   "source": [
    "input_str=input(\"意味類似度ネットワークを作りたい単語を入力してください===>\")\n",
    "\n",
    "# dataframeをいったん作成する\n",
    "data = {\n",
    "    'input': ['群馬県', '栃木'],\n",
    "    'similar_words': [[0.7760874032974243], [0.7456161379814148]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for i in range(3):\n",
    "    # 似ている単語TOP7を書き出す\n",
    "    out = model.wv.most_similar(positive=[input_str], topn=3)\n",
    "\n",
    "    #AtCoderでよく使う辞書処理を使って県と数値を取り出す\n",
    "    pre=[]\n",
    "    pre.append(input_str)\n",
    "    for prefecture, value in out:\n",
    "        print(prefecture,\"\\t\",value)\n",
    "        pre.append(prefecture)    \n",
    "        # キーが既存の場合は値を加算し、存在しない場合は新しい行をDataFrameに追加する\n",
    "        # prefectureでキーが存在するか確認\n",
    "        # 存在した場合は値を追加\n",
    "        # 存在しなかった場合は新たにdfに追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "群馬県 \t 0.7760874032974243\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No axis named 1 for object type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\IRSL27\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:513\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[0;32m    514\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m similar_words\u001b[39m.\u001b[39mappend(prefecture)\n\u001b[0;32m     22\u001b[0m \u001b[39m# キーが既存の場合は値を加算し、存在しない場合は新しい行をDataFrameに追加する\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m((df[\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39;49m prefecture)\u001b[39m.\u001b[39;49mall(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)):\n\u001b[0;32m     24\u001b[0m     existing_indices \u001b[39m=\u001b[39m df[df[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m prefecture]\u001b[39m.\u001b[39mindex\n\u001b[0;32m     25\u001b[0m     existing_row \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[existing_indices[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\IRSL27\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:11356\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.all\u001b[1;34m(self, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[0;32m  11339\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m  11340\u001b[0m     _bool_doc,\n\u001b[0;32m  11341\u001b[0m     desc\u001b[39m=\u001b[39m_all_desc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11354\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11355\u001b[0m ):\n\u001b[1;32m> 11356\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39mall(\u001b[39mself\u001b[39m, axis, bool_only, skipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\IRSL27\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:11028\u001b[0m, in \u001b[0;36mNDFrame.all\u001b[1;34m(self, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[0;32m  11021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m  11022\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  11023\u001b[0m     axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11026\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11027\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m bool_t:\n\u001b[1;32m> 11028\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logical_func(\n\u001b[0;32m  11029\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnanall, axis, bool_only, skipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m  11030\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\IRSL27\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:11001\u001b[0m, in \u001b[0;36mNDFrame._logical_func\u001b[1;34m(self, name, func, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[0;32m  10998\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bool_data()\n\u001b[0;32m  10999\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_reduce_axis1(name, func, skipna\u001b[39m=\u001b[39mskipna)\n\u001b[1;32m> 11001\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  11002\u001b[0m     func,\n\u001b[0;32m  11003\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m  11004\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m  11005\u001b[0m     skipna\u001b[39m=\u001b[39;49mskipna,\n\u001b[0;32m  11006\u001b[0m     numeric_only\u001b[39m=\u001b[39;49mbool_only,\n\u001b[0;32m  11007\u001b[0m     filter_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m  11008\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\IRSL27\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4648\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4645\u001b[0m delegate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m   4647\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4648\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis_number(axis)\n\u001b[0;32m   4650\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delegate, ExtensionArray):\n\u001b[0;32m   4651\u001b[0m     \u001b[39m# dispatch to ExtensionArray interface\u001b[39;00m\n\u001b[0;32m   4652\u001b[0m     \u001b[39mreturn\u001b[39;00m delegate\u001b[39m.\u001b[39m_reduce(name, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\IRSL27\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:515\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[0;32m    514\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo axis named \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m for object type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No axis named 1 for object type Series"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_str = input(\"意味類似度ネットワークを作りたい単語を入力してください===>\")\n",
    "\n",
    "# dataframeをいったん作成する\n",
    "data = [\n",
    "    [['群馬県'], [0.7760874032974243]],\n",
    "    [['栃木'], [0.7456161379814148]]\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for i in range(3):\n",
    "    # 似ている単語TOP7を書き出す\n",
    "    out = model.wv.most_similar(positive=[input_str], topn=3)\n",
    "\n",
    "    # AtCoderでよく使う辞書処理を使って県と数値を取り出す\n",
    "    similar_words = [input_str]\n",
    "    for prefecture, value in out:\n",
    "        print(prefecture, \"\\t\", value)\n",
    "        similar_words.append(prefecture)\n",
    "\n",
    "        # キーが既存の場合は値を加算し、存在しない場合は新しい行をDataFrameに追加する\n",
    "        if any((df[0] == prefecture).all(axis=1)):\n",
    "            existing_indices = df[df[0] == prefecture].index\n",
    "            existing_row = df.loc[existing_indices[0]]\n",
    "            existing_row[1].extend([value])\n",
    "            df.loc[existing_indices[0]] = existing_row\n",
    "        else:\n",
    "            new_row = pd.DataFrame([[prefecture], [[value]]])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
